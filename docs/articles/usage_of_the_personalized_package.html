<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Usage of the Personalized Package • personalized</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">


<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>

<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-vignette">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">personalized</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../articles/index.html">Articles</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      
<div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Usage of the Personalized Package</h1>
                        <h4 class="author">Jared Huling</h4>
            
            <h4 class="date">2017-05-27</h4>
          </div>

    
    
<div class="contents">
<div id="introduction-to-personalized" class="section level1">
<h1>Introduction to <code>personalized</code></h1>
<p>The <code>personalized</code> package aims to provide an entire analysis pipeline that encompasses a broad class of statistical methods for subgroup identification / personalized medicine.</p>
<p>The general analysis pipeline is as follows:</p>
<ol style="list-style-type: decimal">
<li>Construct propensity score function and check propensity score diagnostics</li>
<li>Choose and fit a subgroup identification model</li>
<li>Estimate the resulting treatment effects among estimated subgroups</li>
<li>Visualize and examine model and subgroup treatment effects</li>
</ol>
<p>The available subgroup identification models are those under the purview of the general subgroup identification framework proposed by Chen, et al. (2017). In this section we will give a brief summary of this framework and what elements of it are available in the <code>personalized</code> package.</p>
<p>In general we are interested in understanding the impact of a treatment on an outcome and in particular determining if and how different patients respond differently to a treatment in terms of their expected outcome. Assume the outcome we observe <span class="math inline">\(Y\)</span> is such that larger values are preferable. In addition to the outcome, we also observe patient covariate information <span class="math inline">\(X \in \mathbb{R}^p\)</span> and the treatment status <span class="math inline">\(T \in \{-1,1\}\)</span>, where <span class="math inline">\(T = 1\)</span> indicates that a patient received the treatment, and <span class="math inline">\(T = -1\)</span> indicates as patient observed the control. For the purposes of this package, we assume that the expected outcome conditional on the covariate and treatment status information can be represented by <span class="math display">\[E(Y|X, T) = g(X) + T\Delta(X).\]</span> Here, <span class="math inline">\(\Delta(X)\)</span> represents the interaction between treatment and covariates and <span class="math inline">\(g(X)\)</span> represents the main effects of the patient covariate information on the outcome.</p>
<p>We call the term <span class="math inline">\(\Delta(X)\)</span> a benefit score, as it reflects how much a patient is expected to benefit from a treatment in terms of their outcome. For a patient with <span class="math inline">\(X = x\)</span>, if <span class="math inline">\(\Delta(x) &gt; 0\)</span> (assuming larger outcomes are better), the treatment is beneficial in terms of the expected outcome, and if <span class="math inline">\(\Delta(X) \leq 0\)</span>, the control is better than the treatment. Hence to identify which subgroup of patients benefits from a treatment, we seek to estimate <span class="math inline">\(\Delta(X)\)</span>.</p>
<p>In the framework of Chen, et al. (2017), there are two main methods for estimating subgroups. The first is called the weighting method. The weighting method estimates <span class="math inline">\(\Delta(X)\)</span> by minimizing the following objective function with respect to <span class="math inline">\(f(X)\)</span>: <span class="math display">\[L_W(f) = \frac{1}{n}\sum_{i = 1}^n\frac{(Y_i -  T_i\times f(x_i)) ^ 2}{ {T_i\pi(x_i)+(1-T_i)/2} },\]</span> where <span class="math inline">\(\pi(x) = Pr(T = 1|X = x)\)</span> is the propensity score function. Here, <span class="math inline">\(\hat{f}\)</span> is our estimated benefit score. Hence <span class="math inline">\(\hat{f} = \mbox{argmin}_f L_W(f)\)</span> is our estimate of <span class="math inline">\(\Delta(X)\)</span>. If we want a simple functional form for the estimate <span class="math inline">\(\hat{f}\)</span>, we can restrict <span class="math inline">\(f\)</span> such that it is a linear combination of the covariates, i.e. <span class="math inline">\(f(X) = X^T\beta\)</span>. Hence <span class="math inline">\(\hat{f}(X) = X^T\hat{\beta}\)</span>.</p>
<p>The A-learning estimator is the minimizer of <span class="math display">\[L_A(f) = \frac{1}{n}\sum_{i = 1}^n (Y_i - {\{(T_i+1)/2 -\pi(x_i)\} } {\times f(x_i))^2}.\]</span></p>
<div id="choice-of-m-function" class="section level3">
<h3>Choice of <span class="math inline">\(M\)</span> function</h3>
<p>The <code>personalized</code> package offers a flexible range of choices both for the form of <span class="math inline">\(f(X)\)</span> and also for the loss function <span class="math inline">\(M(y, v)\)</span>. Every choice of <span class="math inline">\(f\)</span> and <span class="math inline">\(M\)</span> can be used for either the weighting method or for the A-learning method. In this package, we limit the use of <span class="math inline">\(M\)</span> to natural choices corresponding to the type of outcome. For example, the squared error loss <span class="math inline">\(M(y, v) = (v - y) ^ 2\)</span> corresponds to continuous responses; the logistic loss <span class="math inline">\(M(y, v) = y \cdot log(1 + \exp\{-v\})\)</span> corresponds to binary outcomes, and the loss associated with the negative partial likelihood of the Cox proportional hazards model corresponds to time-to-event outcomes.</p>
</div>
<div id="choice-of-f" class="section level3">
<h3>Choice of <span class="math inline">\(f\)</span></h3>
<p>The choices of <span class="math inline">\(f\)</span> offered in the <code>personalized</code> package are varied. A familiar, interpretable choice of <span class="math inline">\(f(X)\)</span> is <span class="math inline">\(X^T\beta\)</span>. Also offered is an additive model, i.e. <span class="math inline">\(f(X) = \sum_{j = 1}^pf_j(X_j)\)</span>; this option is accessed through use of the <code>mgcv</code> package, which provides estimation procedures for generalized additive models (GAMs). Another flexible, but less interpretable choice offered here is related to gradient boosted decision trees, which model <span class="math inline">\(f\)</span> as <span class="math inline">\(f(X) = \sum_{k = 1}^Kf_K(X)\)</span>, where each <span class="math inline">\(f_K\)</span> is a decision tree model.</p>
</div>
<div id="variable-selection" class="section level3">
<h3>Variable Selection</h3>
<p>For subgroup identification models with <span class="math inline">\(f(X) = X^T\beta\)</span>, the <code>personalized</code> package also allows for variable selection. Instead of minimizing <span class="math inline">\(L_W(f)\)</span> or <span class="math inline">\(L_A(f)\)</span>, we instead minimize a penalized version: <span class="math inline">\(L_W(f) + \lambda||\beta||_1\)</span> or <span class="math inline">\(L_A(f) + \lambda||\beta||_1\)</span>.</p>
</div>
</div>
<div id="user-guide" class="section level1">
<h1>User Guide</h1>
<p>The user guide for the <code>personalized</code> package will begin with a quick usage reference so users can quickly get started with a subgroup identification analysis. Following the quick usage reference, the user guide will expand on all the options available in the main functions and the implications of the various options.</p>
<div id="quick-usage-reference" class="section level2">
<h2>Quick Usage Reference</h2>
<p>First simulate some data where we know the truth. In this simulation, the treatment assignment depends on covariates and hence we must model the propensity score <span class="math inline">\(\pi(x) = Pr(T = 1 | X = x)\)</span>. In this simulation we will assume that larger values of the outcome are better.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(personalized)

<span class="kw">set.seed</span>(<span class="dv">123</span>)
n.obs  &lt;-<span class="st"> </span><span class="dv">1000</span>
n.vars &lt;-<span class="st"> </span><span class="dv">50</span>
x &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n.obs *<span class="st"> </span>n.vars, <span class="dt">sd =</span> <span class="dv">3</span>), n.obs, n.vars)

<span class="co"># simulate non-randomized treatment</span>
xbetat   &lt;-<span class="st"> </span><span class="fl">0.5</span> +<span class="st"> </span><span class="fl">0.25</span> *<span class="st"> </span>x[,<span class="dv">21</span>] -<span class="st"> </span><span class="fl">0.25</span> *<span class="st"> </span>x[,<span class="dv">41</span>]
trt.prob &lt;-<span class="st"> </span><span class="kw">exp</span>(xbetat) /<span class="st"> </span>(<span class="dv">1</span> +<span class="st"> </span><span class="kw">exp</span>(xbetat))
trt      &lt;-<span class="st"> </span><span class="kw">rbinom</span>(n.obs, <span class="dv">1</span>, <span class="dt">prob =</span> trt.prob)

<span class="co"># simulate delta</span>
delta &lt;-<span class="st"> </span>(<span class="fl">0.5</span> +<span class="st"> </span>x[,<span class="dv">2</span>] -<span class="st"> </span><span class="fl">0.5</span> *<span class="st"> </span>x[,<span class="dv">3</span>] -<span class="st"> </span><span class="dv">1</span> *<span class="st"> </span>x[,<span class="dv">11</span>] +<span class="st"> </span><span class="dv">1</span> *<span class="st"> </span>x[,<span class="dv">1</span>] *<span class="st"> </span>x[,<span class="dv">12</span>] )

<span class="co"># simulate main effects g(X)</span>
xbeta &lt;-<span class="st"> </span>x[,<span class="dv">1</span>] +<span class="st"> </span>x[,<span class="dv">11</span>] -<span class="st"> </span><span class="dv">2</span> *<span class="st"> </span>x[,<span class="dv">12</span>]^<span class="dv">2</span> +<span class="st"> </span>x[,<span class="dv">13</span>] +<span class="st"> </span><span class="fl">0.5</span> *<span class="st"> </span>x[,<span class="dv">15</span>] ^<span class="st"> </span><span class="dv">2</span>
xbeta &lt;-<span class="st"> </span>xbeta +<span class="st"> </span>delta *<span class="st"> </span>(<span class="dv">2</span> *<span class="st"> </span>trt -<span class="st"> </span><span class="dv">1</span>)

<span class="co"># simulate continuous outcomes</span>
y &lt;-<span class="st"> </span><span class="kw">drop</span>(xbeta) +<span class="st"> </span><span class="kw">rnorm</span>(n.obs)</code></pre></div>
<div id="creating-and-checking-propensity-score-model" class="section level3">
<h3>Creating and Checking Propensity Score Model</h3>
<p>The first step in our analysis is to construct a model for the propensity score. In the <code>personalized</code> package, we need to wrap this model in a function which inputs covariate values and the treatment statuses and outputs a propensity score between 0 and 1. Since there are many covariates, we use the lasso to select variables in our propensity score model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create function for fitting propensity score model</span>
prop.func &lt;-<span class="st"> </span>function(x, trt)
{
 <span class="co"># fit propensity score model</span>
 propens.model &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(<span class="dt">y =</span> trt,
                            <span class="dt">x =</span> x, 
                            <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)
 pi.x &lt;-<span class="st"> </span><span class="kw">predict</span>(propens.model, <span class="dt">s =</span> <span class="st">&quot;lambda.min&quot;</span>,
                 <span class="dt">newx =</span> x, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)[,<span class="dv">1</span>]
 pi.x
}</code></pre></div>
<p>We then need to make sure the propensity scores have sufficient overlap between treatment groups. We can do this with the <code>check.overlap()</code> function, which plots densities or histograms of the propensity scores for each of the treatment groups:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">check.overlap</span>(x, trt, prop.func)</code></pre></div>
<p><img src="usage_of_the_personalized_package_files/figure-html/plot_overlap-1.png" width="672" /></p>
<p>We can see that our propensity scores have common support.</p>
</div>
<div id="fitting-subgroup-identification-model" class="section level3">
<h3>Fitting Subgroup Identification Model</h3>
<p>The next step is to choose and fit a subgroup identification model. In this example, the outcome is continuous, so we choose the squared error loss function. We also choose the model type (either the weighting or the A-learning method). The main funciton for fitting subgroup identification models is <code>fit.subgroup</code>. Since there are many covariates, we choose a loss function with a lasso penalty to select variables. The underlying fitting function here is <code>cv.glmnet()</code>. We can pass to <code>fit.subgroup()</code> arguments of the <code>cv.glmnet()</code> function, such as <code>nfolds</code> for the number of cross validation folds.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">subgrp.model &lt;-<span class="st"> </span><span class="kw">fit.subgroup</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y,
                             <span class="dt">trt =</span> trt,
                             <span class="dt">propensity.func =</span> prop.func,
                             <span class="dt">family =</span> <span class="st">&quot;gaussian&quot;</span>,
                             <span class="dt">loss   =</span> <span class="st">&quot;sq_loss_lasso&quot;</span>,
                             <span class="dt">nfolds =</span> <span class="dv">10</span>)              <span class="co"># option for cv.glmnet</span>

<span class="kw">summary</span>(subgrp.model)</code></pre></div>
<pre><code>## family:  gaussian 
## loss:    sq_loss_lasso 
## method:  weighting 
## 
## Average Outcomes:
##                  Recommended Trt   Recommended Ctrl
## Received Trt   -7.6066 (n = 303) -19.1473 (n = 287)
## Received Ctrl -16.6438 (n = 212)  -8.9658 (n = 198)
## 
##  Trt  Effect Among Recommended Trt Ctrl Effect Among Recommended Ctrl 
##                   9.0372 (n = 515)                  10.1815 (n = 485) 
## 
## Benefit score quantiles: 
##       0%      25%      50%      75%     100% 
## -11.0842  -2.1026   0.1319   2.0584   9.7386 
## 
## 8 variables selected by the lasso (cross validation criterion).
## 
##        Estimate
## V1   0.05794759
## V2   0.65747101
## V3  -0.45725571
## V6  -0.10531434
## V11 -0.39937925
## V13  0.30203536
## V17  0.24494122
## V37 -0.17585886</code></pre>
<p>We can then plot the outcomes of patients in the different subgroups:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(subgrp.model)</code></pre></div>
<p><img src="usage_of_the_personalized_package_files/figure-html/plot_model-1.png" width="672" /></p>
<p>Alternatively, we can create an interaction plot. This plot represents the average outcome within each subgroup broken down by treatment status. If the lines in the interaction plots cross, that indicates there is a subgroup treatment effect.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(subgrp.model, <span class="dt">type =</span> <span class="st">&quot;interaction&quot;</span>)</code></pre></div>
<p><img src="usage_of_the_personalized_package_files/figure-html/plot_model_2-1.png" width="672" /></p>
</div>
<div id="evaluating-effect-of-subgroup-identification-model" class="section level3">
<h3>Evaluating Effect of Subgroup Identification Model</h3>
<p>Unfortunately, if we simply look at the average outcome within each subgroup, this will give us a biased estimate of the treatment effects within each subgroup as we have already used the data to estimate the subgroups. Instead, to get a valid estimate of the subgroup treatment effects we can use a bootstrap approach to correcting for this bias. We can alternatively repeatedly partition our data into training and testing samples. In this procedure for each replication we fit a subgroup model using the training data and then evaluate the subgroup treatment effects on the testing data. The argument <code>B</code> specifies the number of replications and the argument <code>train.fraction</code> specifies what proportion of samples are for training in the training and testing partitioning method.</p>
<p>Both of these approaches can be carried out using the <code>validate.subgroup()</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">validation &lt;-<span class="st"> </span><span class="kw">validate.subgroup</span>(subgrp.model, 
                                <span class="dt">B =</span> 25L,  <span class="co"># specify the number of replications</span>
                                <span class="dt">method =</span> <span class="st">&quot;training_test_replication&quot;</span>,
                                <span class="dt">train.fraction =</span> <span class="fl">0.75</span>)

validation</code></pre></div>
<pre><code>## family:  gaussian 
## loss:    sq_loss_lasso 
## method:  weighting 
## 
## validation method:  training_test_replication 
## 
## Average Test Set Outcomes:
##                      Recommended Trt       Recommended Ctrl
## Received Trt   -8.7808 (SE = 4.3435)  -15.878 (SE = 2.5123)
## Received Ctrl -12.7171 (SE = 5.2784) -11.6575 (SE = 3.5258)
## 
##  Trt  Effect Among Recommended Trt Ctrl Effect Among Recommended Ctrl 
##               3.9363 (SE = 4.0607)               4.2205 (SE = 4.6719)</code></pre>
<p>We can then plot the average outcomes averaged over all replications of the training and testing partition procedure:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(validation)</code></pre></div>
<p><img src="usage_of_the_personalized_package_files/figure-html/plot_validation-1.png" width="672" /> From the above plot we can evaluate what the impact of the subgroups is. Among patients for whom the model recommends the control is more effective than the treatment, we can see that those who instead take the treatment are worse off than patients who take the control. Similarly, among patients who are recommended the treatment, patients who take the treatment are better off on average than patients who do not take the treatment.</p>
<p>Similarly, we can create an interaction plot of either the bootstrap bias-corrected means within the different subgroups or the average test set means within subgroups. Here, lines crossing is an indicator of differential treatment effect between the subgroups.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(validation, <span class="dt">type =</span> <span class="st">&quot;interaction&quot;</span>)</code></pre></div>
<p><img src="usage_of_the_personalized_package_files/figure-html/plot_validation_2-1.png" width="672" /></p>
<p>We can also compare the validation results with the results on the observed data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plotCompare</span>(subgrp.model, validation, <span class="dt">type =</span> <span class="st">&quot;interaction&quot;</span>)</code></pre></div>
<p><img src="usage_of_the_personalized_package_files/figure-html/plot_validation_compare-1.png" width="672" /></p>
<p>Note that the estimated treatment effects within subgroups are attenuated for the validated results. It is common for the estimated treatment effects within subgroups to be overly-optimistic based on the training data.</p>
</div>
</div>
<div id="fitting-subgroup-identification-models" class="section level2">
<h2>Fitting Subgroup Identification Models</h2>
<div id="section" class="section level3">
<h3></h3>
</div>
<div id="continuous-outcomes" class="section level3">
<h3>Continuous Outcomes</h3>
</div>
<div id="binary-outcomes" class="section level3">
<h3>Binary Outcomes</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create binary outcomes</span>
y.binary &lt;-<span class="st"> </span><span class="dv">1</span> *<span class="st"> </span>(xbeta +<span class="st"> </span><span class="kw">rnorm</span>(n.obs, <span class="dt">sd =</span> <span class="dv">2</span>) &gt;<span class="st"> </span><span class="dv">0</span> )</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">subgrp.bin &lt;-<span class="st"> </span><span class="kw">fit.subgroup</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y.binary,
                           <span class="dt">trt =</span> trt,
                           <span class="dt">propensity.func =</span> prop.func,
                           <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>,
                           <span class="dt">loss   =</span> <span class="st">&quot;logistic_loss_lasso&quot;</span>,
                           <span class="dt">nfolds =</span> <span class="dv">10</span>)      <span class="co"># option for cv.glmnet</span></code></pre></div>
<p>When gradient-boosted decision trees are used for <span class="math inline">\(f(X)\)</span> by the package <code>gbm</code>, care must be taken to choose the hyperparameters effectively. Specifically, <code>shrinkage</code> (similar to the step-size in gradient descent), <code>n.trees</code> (the number of trees to fit), and <code>interaction.depth</code> (the maximum depth of each tree) should be tuned according to the data at hand. By default for gradient-boosting models, <code>fit.subgroup</code> plots the cross validation error versus the number of trees to give the user a sense of if their choice of tuning parameters is effective.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">subgrp.bin2 &lt;-<span class="st"> </span><span class="kw">fit.subgroup</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y.binary,
                            <span class="dt">trt =</span> trt,
                            <span class="dt">propensity.func =</span> prop.func,
                            <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>,
                            <span class="dt">loss =</span> <span class="st">&quot;logistic_loss_gbm&quot;</span>,
                            <span class="dt">shrinkage =</span> <span class="fl">0.025</span>,  <span class="co"># options for gbm</span>
                            <span class="dt">n.trees =</span> <span class="dv">1500</span>, 
                            <span class="dt">interaction.depth =</span> <span class="dv">3</span>,
                            <span class="dt">cv.folds =</span> <span class="dv">5</span>)      </code></pre></div>
<p><img src="usage_of_the_personalized_package_files/figure-html/fit_binary_2-1.png" width="672" /></p>
<p>We can see that at least on the training data, the performance of the gradient-boosting model is better.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">subgrp.bin</code></pre></div>
<pre><code>## family:  binomial 
## loss:    logistic_loss_lasso 
## method:  weighting 
## 
## Average Outcomes:
##                Recommended Trt Recommended Ctrl
## Received Trt  0.4505 (n = 333) 0.2179 (n = 257)
## Received Ctrl 0.1858 (n = 226) 0.4565 (n = 184)
## 
##  Trt  Effect Among Recommended Trt Ctrl Effect Among Recommended Ctrl 
##                   0.2646 (n = 559)                   0.2386 (n = 441) 
## 
## Benefit score quantiles: 
##       0%      25%      50%      75%     100% 
## -1.71039 -0.31334  0.07145  0.44287  1.55721</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">subgrp.bin2</code></pre></div>
<pre><code>## family:  binomial 
## loss:    logistic_loss_gbm 
## method:  weighting 
## 
## Average Outcomes:
##                Recommended Trt Recommended Ctrl
## Received Trt  0.9902 (n = 204) 0.0104 (n = 386)
## Received Ctrl    0.5 (n = 114) 0.2331 (n = 296)
## 
##  Trt  Effect Among Recommended Trt Ctrl Effect Among Recommended Ctrl 
##                   0.4902 (n = 318)                   0.2227 (n = 682) 
## 
## Benefit score quantiles: 
##      0%     25%     50%     75%    100% 
## -5.8487 -3.0579 -1.5847  0.6122  4.8357</code></pre>
</div>
<div id="time-to-event-outcomes" class="section level3">
<h3>Time-to-event Outcomes</h3>
<p>First we will generate time-to-event outcomes to illustrate usage of the <code>fit.subgroup()</code> model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create time-to-event outcomes</span>
surv.time &lt;-<span class="st"> </span><span class="kw">exp</span>(-<span class="dv">20</span> -<span class="st"> </span>xbeta +<span class="st"> </span><span class="kw">rnorm</span>(n.obs, <span class="dt">sd =</span> <span class="dv">1</span>))
cens.time &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="kw">rnorm</span>(n.obs, <span class="dt">sd =</span> <span class="dv">3</span>))
y.time.to.event  &lt;-<span class="st"> </span><span class="kw">pmin</span>(surv.time, cens.time)
status           &lt;-<span class="st"> </span><span class="dv">1</span> *<span class="st"> </span>(surv.time &lt;=<span class="st"> </span>cens.time)</code></pre></div>
<p>For subgroup identification models for time-to-event outcomes, the user should provide <code>fit.subgroup()</code> with a <code>Surv</code> object for <code>y</code>. This can be done like the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(survival)
<span class="kw">set.seed</span>(<span class="dv">123</span>)
subgrp.cox &lt;-<span class="st"> </span><span class="kw">fit.subgroup</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> <span class="kw">Surv</span>(y.time.to.event, status),
                           <span class="dt">trt =</span> trt,
                           <span class="dt">propensity.func =</span> prop.func,
                           <span class="dt">method =</span> <span class="st">&quot;weighting&quot;</span>,
                           <span class="dt">family =</span> <span class="st">&quot;cox&quot;</span>,
                           <span class="dt">loss   =</span> <span class="st">&quot;cox_loss_lasso&quot;</span>,
                           <span class="dt">nfolds =</span> <span class="dv">10</span>)      <span class="co"># option for cv.glmnet</span></code></pre></div>
<p>The subgroup treatment effects are estimated using the restricted mean statistic and can be displayed with <code>summary.subgroup_fitted()</code> or <code>print.subgroup_fitted()</code> like the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(subgrp.cox)</code></pre></div>
<pre><code>## family:  cox 
## loss:    cox_loss_lasso 
## method:  weighting 
## 
## Average Outcomes:
##                  Recommended Trt   Recommended Ctrl
## Received Trt  450.0395 (n = 291) 544.4105 (n = 299)
## Received Ctrl 856.3652 (n = 202) 357.6865 (n = 208)
## 
##  Trt  Effect Among Recommended Trt Ctrl Effect Among Recommended Ctrl 
##                -406.3257 (n = 493)                -186.7239 (n = 507) 
## 
## Benefit score quantiles: 
##        0%       25%       50%       75%      100% 
## -0.464795 -0.126504 -0.007506  0.119531  0.732182 
## 
## 7 variables selected by the lasso (cross validation criterion).
## 
##         Estimate
## V1   0.002572413
## V2   0.047467290
## V3  -0.009058425
## V11 -0.027768974
## V13  0.003981027
## V47 -0.001620790
## V50  0.015431938</code></pre>
</div>
<div id="plotting" class="section level3">
<h3>Plotting</h3>
</div>
</div>
<div id="validating-subgroup-identification-models" class="section level2">
<h2>Validating Subgroup Identification Models</h2>
<div id="repeated-trainingtest-splitting" class="section level3">
<h3>Repeated Training/Test Splitting</h3>
</div>
<div id="bootstrap-bias-correction" class="section level3">
<h3>Bootstrap Bias Correction</h3>
</div>
</div>
</div>
<div id="reference-manual" class="section level1">
<h1>Reference Manual</h1>
<div id="check.overlap" class="section level2">
<h2><code>check.overlap()</code></h2>
<p>The primary function of <code>check.overlap()</code> is to visualize the estimated propensity scores to evaluate whether there is sufficient overlap of the propensity scores between treatment groups. Overlap is required for the validity of propensity score based methods.</p>
</div>
<div id="fit.subgroup" class="section level2">
<h2><code>fit.subgroup()</code></h2>
<p>The primary function of <code>fit.subgroup()</code> is to estimate the parameters in a subgroup identification model.</p>
</div>
<div id="validate.subgroup" class="section level2">
<h2><code>validate.subgroup()</code></h2>
<p>The function of <code>validate.subgroup()</code> is to evaluate the impact of an estimated subgroup. In particular, <code>validate.subgroup()</code> provides methods to determine if treatment effects are truly different between the different estimated subgroups.</p>
</div>
<div id="plot.subgroup_fitted-plot.subgroup_validated-and-plotcompare" class="section level2">
<h2><code>plot.subgroup_fitted()</code>, <code>plot.subgroup_validated()</code>, and <code>plotCompare()</code></h2>
<p>These functions plot the outcomes or average outcomes within both subgroups and treatment groups. This can give users a sense of the impact of the estimated subgroups. The <code>plotCompare()</code> function allows users to make plots which compare multiple subgroup identification models or validation results.</p>
</div>
<div id="predict.subgroup_fitted" class="section level2">
<h2><code>predict.subgroup_fitted()</code></h2>
<p>The function <code>predict.subgroup_fitted()</code> allows users to estimate the benefit score (<span class="math inline">\(\hat{f}(X)\)</span>) for new patients. The benefit score is used to assign patients to treatment groups based on a particular subgroup identification model, i.e. if <span class="math inline">\(f(x) &gt; 0\)</span>, then a patient with <span class="math inline">\(X = x\)</span> should be assigned to the treatment group to maximize their expected outcome.</p>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2>Contents</h2>
      <ul>
      <li><a href="#introduction-to-personalized">Introduction to <code>personalized</code></a></li>
      <li><a href="#user-guide">User Guide</a><ul>
      <li><a href="#quick-usage-reference">Quick Usage Reference</a></li>
      <li><a href="#fitting-subgroup-identification-models">Fitting Subgroup Identification Models</a></li>
      <li><a href="#validating-subgroup-identification-models">Validating Subgroup Identification Models</a></li>
      </ul></li>
      <li><a href="#reference-manual">Reference Manual</a><ul>
      <li><a href="#check.overlap"><code>check.overlap()</code></a></li>
      <li><a href="#fit.subgroup"><code>fit.subgroup()</code></a></li>
      <li><a href="#validate.subgroup"><code>validate.subgroup()</code></a></li>
      <li><a href="#plot.subgroup_fitted-plot.subgroup_validated-and-plotcompare"><code>plot.subgroup_fitted()</code>, <code>plot.subgroup_validated()</code>, and <code>plotCompare()</code></a></li>
      <li><a href="#predict.subgroup_fitted"><code>predict.subgroup_fitted()</code></a></li>
      </ul></li>
      </ul>
    </div>
      </div>

</div>


      <footer>
      <div class="copyright">
  <p>Developed by Jared Huling.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>
